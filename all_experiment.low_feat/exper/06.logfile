./em.sh 100
final_regressor = model/iter001.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
gzip: data/iter000.labeled.train.nonshared.table.gz: No such file or directory
0.228786 0.212185       524288       524288.0    known        0        2
0.219254 0.209721      1048576      1048576.0    known        0        2
0.214540 0.209827      2097152      2097152.0    known        0        2

finished run
number of examples per pass = 282808
passes used = 10
weighted example sum = 2828080.000000
weighted label sum = 0.000000
average loss = 0.213391
total feature number = 5656160
only testing
raw predictions = tmp/iter001.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter002.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.221114 0.196839       524288       524288.0    known        1        4
0.205176 0.189239      1048576      1048576.0    known        0        4
0.196956 0.188736      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.194361
total feature number = 11524636
only testing
raw predictions = tmp/iter002.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter003.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.165360 0.085331       524288       524288.0    known        1        4
0.114617 0.063875      1048576      1048576.0    known        0        4
0.088557 0.062496      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.080270
total feature number = 11524636
only testing
raw predictions = tmp/iter003.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter004.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.149387 0.053386       524288       524288.0    known        1        4
0.086898 0.024409      1048576      1048576.0    known        0        4
0.054274 0.021651      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.043960
total feature number = 11524636
only testing
raw predictions = tmp/iter004.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter005.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.147001 0.048615       524288       524288.0    known        1        4
0.082225 0.017449      1048576      1048576.0    known        0        4
0.048300 0.014374      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.037606
total feature number = 11524636
only testing
raw predictions = tmp/iter005.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter006.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.146386 0.047385       524288       524288.0    known        1        4
0.081063 0.015739      1048576      1048576.0    known        0        4
0.046826 0.012590      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.036045
total feature number = 11524636
only testing
raw predictions = tmp/iter006.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter007.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.146045 0.046703       524288       524288.0    known        1        4
0.080527 0.015008      1048576      1048576.0    known        0        4
0.046165 0.011804      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.035343
total feature number = 11524636
only testing
raw predictions = tmp/iter007.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter008.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145907 0.046426       524288       524288.0    known        1        4
0.080236 0.014565      1048576      1048576.0    known        0        4
0.045771 0.011306      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.034923
total feature number = 11524636
only testing
raw predictions = tmp/iter008.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter009.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145795 0.046203       524288       524288.0    known        1        4
0.080006 0.014217      1048576      1048576.0    known        0        4
0.045478 0.010951      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.034622
total feature number = 11524636
only testing
raw predictions = tmp/iter009.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter010.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145718 0.046049       524288       524288.0    known        1        4
0.079820 0.013921      1048576      1048576.0    known        0        4
0.045255 0.010690      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.034387
total feature number = 11524636
only testing
raw predictions = tmp/iter010.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter011.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145667 0.045946       524288       524288.0    known        1        4
0.079663 0.013660      1048576      1048576.0    known        0        4
0.045048 0.010433      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.034161
total feature number = 11524636
only testing
raw predictions = tmp/iter011.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter012.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145656 0.045923       524288       524288.0    known        1        4
0.079573 0.013491      1048576      1048576.0    known        0        4
0.044899 0.010224      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033992
total feature number = 11524636
only testing
raw predictions = tmp/iter012.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter013.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145635 0.045883       524288       524288.0    known        1        4
0.079529 0.013422      1048576      1048576.0    known        0        4
0.044825 0.010121      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033906
total feature number = 11524636
only testing
raw predictions = tmp/iter013.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter014.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145632 0.045876       524288       524288.0    known        1        4
0.079486 0.013340      1048576      1048576.0    known        0        4
0.044758 0.010030      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033827
total feature number = 11524636
only testing
raw predictions = tmp/iter014.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter015.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145616 0.045844       524288       524288.0    known        1        4
0.079449 0.013283      1048576      1048576.0    known        0        4
0.044713 0.009976      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033775
total feature number = 11524636
only testing
raw predictions = tmp/iter015.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter016.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145610 0.045832       524288       524288.0    known        1        4
0.079427 0.013244      1048576      1048576.0    known        0        4
0.044671 0.009915      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033724
total feature number = 11524636
only testing
raw predictions = tmp/iter016.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter017.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145583 0.045779       524288       524288.0    known        1        4
0.079384 0.013184      1048576      1048576.0    known        0        4
0.044628 0.009872      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033678
total feature number = 11524636
only testing
raw predictions = tmp/iter017.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter018.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145580 0.045773       524288       524288.0    known        1        4
0.079382 0.013183      1048576      1048576.0    known        0        4
0.044614 0.009845      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033655
total feature number = 11524636
only testing
raw predictions = tmp/iter018.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter019.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145559 0.045730       524288       524288.0    known        1        4
0.079365 0.013170      1048576      1048576.0    known        0        4
0.044601 0.009838      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033642
total feature number = 11524636
only testing
raw predictions = tmp/iter019.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter020.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145546 0.045704       524288       524288.0    known        1        4
0.079331 0.013115      1048576      1048576.0    known        0        4
0.044559 0.009788      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033606
total feature number = 11524636
only testing
raw predictions = tmp/iter020.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter021.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145534 0.045681       524288       524288.0    known        1        4
0.079292 0.013049      1048576      1048576.0    known        0        4
0.044507 0.009722      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033548
total feature number = 11524636
only testing
raw predictions = tmp/iter021.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter022.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145518 0.045647       524288       524288.0    known        1        4
0.079257 0.012996      1048576      1048576.0    known        0        4
0.044467 0.009676      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033503
total feature number = 11524636
only testing
raw predictions = tmp/iter022.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter023.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145499 0.045609       524288       524288.0    known        1        4
0.079233 0.012968      1048576      1048576.0    known        0        4
0.044433 0.009632      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033465
total feature number = 11524636
only testing
raw predictions = tmp/iter023.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter024.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145497 0.045607       524288       524288.0    known        1        4
0.079221 0.012944      1048576      1048576.0    known        0        4
0.044419 0.009618      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033451
total feature number = 11524636
only testing
raw predictions = tmp/iter024.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter025.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145498 0.045607       524288       524288.0    known        1        4
0.079228 0.012958      1048576      1048576.0    known        0        4
0.044416 0.009605      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033448
total feature number = 11524636
only testing
raw predictions = tmp/iter025.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter026.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145522 0.045656       524288       524288.0    known        1        4
0.079247 0.012972      1048576      1048576.0    known        0        4
0.044422 0.009598      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033451
total feature number = 11524636
only testing
raw predictions = tmp/iter026.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter027.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145511 0.045634       524288       524288.0    known        1        4
0.079245 0.012980      1048576      1048576.0    known        0        4
0.044417 0.009589      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033445
total feature number = 11524636
only testing
raw predictions = tmp/iter027.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter028.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145496 0.045603       524288       524288.0    known        1        4
0.079236 0.012975      1048576      1048576.0    known        0        4
0.044408 0.009581      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033434
total feature number = 11524636
only testing
raw predictions = tmp/iter028.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter029.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145488 0.045588       524288       524288.0    known        1        4
0.079230 0.012972      1048576      1048576.0    known        0        4
0.044418 0.009605      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033444
total feature number = 11524636
only testing
raw predictions = tmp/iter029.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter030.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145454 0.045519       524288       524288.0    known        1        4
0.079186 0.012918      1048576      1048576.0    known        0        4
0.044379 0.009572      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033407
total feature number = 11524636
only testing
raw predictions = tmp/iter030.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter031.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145427 0.045466       524288       524288.0    known        1        4
0.079149 0.012872      1048576      1048576.0    known        0        4
0.044333 0.009517      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033361
total feature number = 11524636
only testing
raw predictions = tmp/iter031.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter032.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145427 0.045466       524288       524288.0    known        1        4
0.079131 0.012836      1048576      1048576.0    known        0        4
0.044311 0.009490      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033337
total feature number = 11524636
only testing
raw predictions = tmp/iter032.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter033.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145424 0.045460       524288       524288.0    known        1        4
0.079131 0.012838      1048576      1048576.0    known        0        4
0.044308 0.009485      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033336
total feature number = 11524636
only testing
raw predictions = tmp/iter033.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter034.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145425 0.045463       524288       524288.0    known        1        4
0.079133 0.012840      1048576      1048576.0    known        0        4
0.044305 0.009477      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033334
total feature number = 11524636
only testing
raw predictions = tmp/iter034.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter035.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145414 0.045440       524288       524288.0    known        1        4
0.079116 0.012817      1048576      1048576.0    known        0        4
0.044290 0.009464      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033319
total feature number = 11524636
only testing
raw predictions = tmp/iter035.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter036.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145407 0.045425       524288       524288.0    known        1        4
0.079113 0.012819      1048576      1048576.0    known        0        4
0.044278 0.009443      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033303
total feature number = 11524636
only testing
raw predictions = tmp/iter036.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter037.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145413 0.045437       524288       524288.0    known        1        4
0.079114 0.012816      1048576      1048576.0    known        0        4
0.044274 0.009434      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033296
total feature number = 11524636
only testing
raw predictions = tmp/iter037.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter038.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145400 0.045411       524288       524288.0    known        1        4
0.079112 0.012824      1048576      1048576.0    known        0        4
0.044272 0.009433      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033293
total feature number = 11524636
only testing
raw predictions = tmp/iter038.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter039.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145397 0.045407       524288       524288.0    known        1        4
0.079092 0.012787      1048576      1048576.0    known        0        4
0.044263 0.009435      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033283
total feature number = 11524636
only testing
raw predictions = tmp/iter039.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter040.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145384 0.045379       524288       524288.0    known        1        4
0.079071 0.012758      1048576      1048576.0    known        0        4
0.044254 0.009437      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033278
total feature number = 11524636
only testing
raw predictions = tmp/iter040.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter041.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145379 0.045370       524288       524288.0    known        1        4
0.079054 0.012728      1048576      1048576.0    known        0        4
0.044231 0.009407      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033260
total feature number = 11524636
only testing
raw predictions = tmp/iter041.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter042.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145341 0.045294       524288       524288.0    known        1        4
0.079005 0.012669      1048576      1048576.0    known        0        4
0.044183 0.009361      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033216
total feature number = 11524636
only testing
raw predictions = tmp/iter042.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter043.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145329 0.045269       524288       524288.0    known        1        4
0.078976 0.012624      1048576      1048576.0    known        0        4
0.044156 0.009336      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033189
total feature number = 11524636
only testing
raw predictions = tmp/iter043.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter044.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145318 0.045248       524288       524288.0    known        1        4
0.078960 0.012602      1048576      1048576.0    known        0        4
0.044136 0.009312      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033169
total feature number = 11524636
only testing
raw predictions = tmp/iter044.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter045.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145310 0.045233       524288       524288.0    known        1        4
0.078950 0.012590      1048576      1048576.0    known        0        4
0.044126 0.009302      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033159
total feature number = 11524636
only testing
raw predictions = tmp/iter045.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter046.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145312 0.045236       524288       524288.0    known        1        4
0.078942 0.012573      1048576      1048576.0    known        0        4
0.044117 0.009292      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033151
total feature number = 11524636
only testing
raw predictions = tmp/iter046.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter047.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145314 0.045239       524288       524288.0    known        1        4
0.078935 0.012557      1048576      1048576.0    known        0        4
0.044097 0.009258      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033129
total feature number = 11524636
only testing
raw predictions = tmp/iter047.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter048.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145318 0.045249       524288       524288.0    known        1        4
0.078933 0.012548      1048576      1048576.0    known        0        4
0.044086 0.009240      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033119
total feature number = 11524636
only testing
raw predictions = tmp/iter048.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter049.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145315 0.045241       524288       524288.0    known        1        4
0.078924 0.012533      1048576      1048576.0    known        0        4
0.044077 0.009231      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033109
total feature number = 11524636
only testing
raw predictions = tmp/iter049.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter050.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145312 0.045236       524288       524288.0    known        1        4
0.078905 0.012499      1048576      1048576.0    known        0        4
0.044057 0.009209      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033091
total feature number = 11524636
only testing
raw predictions = tmp/iter050.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter051.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145311 0.045234       524288       524288.0    known        1        4
0.078892 0.012474      1048576      1048576.0    known        0        4
0.044048 0.009204      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033083
total feature number = 11524636
only testing
raw predictions = tmp/iter051.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter052.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145304 0.045221       524288       524288.0    known        1        4
0.078882 0.012459      1048576      1048576.0    known        0        4
0.044038 0.009194      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033071
total feature number = 11524636
only testing
raw predictions = tmp/iter052.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter053.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145303 0.045217       524288       524288.0    known        1        4
0.078878 0.012453      1048576      1048576.0    known        0        4
0.044027 0.009177      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033060
total feature number = 11524636
only testing
raw predictions = tmp/iter053.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter054.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145306 0.045225       524288       524288.0    known        1        4
0.078879 0.012452      1048576      1048576.0    known        0        4
0.044025 0.009170      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033058
total feature number = 11524636
only testing
raw predictions = tmp/iter054.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter055.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145308 0.045227       524288       524288.0    known        1        4
0.078879 0.012450      1048576      1048576.0    known        0        4
0.044028 0.009177      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033062
total feature number = 11524636
only testing
raw predictions = tmp/iter055.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter056.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145302 0.045216       524288       524288.0    known        1        4
0.078876 0.012451      1048576      1048576.0    known        0        4
0.044029 0.009182      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033064
total feature number = 11524636
only testing
raw predictions = tmp/iter056.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter057.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145299 0.045211       524288       524288.0    known        1        4
0.078871 0.012442      1048576      1048576.0    known        0        4
0.044016 0.009161      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033050
total feature number = 11524636
only testing
raw predictions = tmp/iter057.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter058.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145286 0.045184       524288       524288.0    known        1        4
0.078856 0.012427      1048576      1048576.0    known        0        4
0.044000 0.009144      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033034
total feature number = 11524636
only testing
raw predictions = tmp/iter058.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter059.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145278 0.045168       524288       524288.0    known        1        4
0.078849 0.012420      1048576      1048576.0    known        0        4
0.043996 0.009142      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033029
total feature number = 11524636
only testing
raw predictions = tmp/iter059.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter060.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145278 0.045167       524288       524288.0    known        1        4
0.078850 0.012422      1048576      1048576.0    known        0        4
0.043996 0.009143      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033029
total feature number = 11524636
only testing
raw predictions = tmp/iter060.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter061.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145280 0.045171       524288       524288.0    known        1        4
0.078850 0.012421      1048576      1048576.0    known        0        4
0.043996 0.009141      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033030
total feature number = 11524636
only testing
raw predictions = tmp/iter061.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter062.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145291 0.045194       524288       524288.0    known        1        4
0.078849 0.012407      1048576      1048576.0    known        0        4
0.043993 0.009137      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033025
total feature number = 11524636
only testing
raw predictions = tmp/iter062.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter063.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145291 0.045194       524288       524288.0    known        1        4
0.078848 0.012406      1048576      1048576.0    known        0        4
0.043989 0.009130      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033020
total feature number = 11524636
only testing
raw predictions = tmp/iter063.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter064.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145293 0.045198       524288       524288.0    known        1        4
0.078845 0.012397      1048576      1048576.0    known        0        4
0.043986 0.009126      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033016
total feature number = 11524636
only testing
raw predictions = tmp/iter064.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter065.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145288 0.045188       524288       524288.0    known        1        4
0.078840 0.012393      1048576      1048576.0    known        0        4
0.043983 0.009125      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033012
total feature number = 11524636
only testing
raw predictions = tmp/iter065.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter066.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145291 0.045195       524288       524288.0    known        1        4
0.078841 0.012391      1048576      1048576.0    known        0        4
0.043985 0.009129      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033013
total feature number = 11524636
only testing
raw predictions = tmp/iter066.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter067.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145294 0.045200       524288       524288.0    known        1        4
0.078848 0.012402      1048576      1048576.0    known        0        4
0.043991 0.009135      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033017
total feature number = 11524636
only testing
raw predictions = tmp/iter067.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter068.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145295 0.045202       524288       524288.0    known        1        4
0.078845 0.012394      1048576      1048576.0    known        0        4
0.043986 0.009127      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033013
total feature number = 11524636
only testing
raw predictions = tmp/iter068.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter069.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145299 0.045210       524288       524288.0    known        1        4
0.078845 0.012391      1048576      1048576.0    known        0        4
0.043982 0.009120      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033008
total feature number = 11524636
only testing
raw predictions = tmp/iter069.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter070.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145300 0.045212       524288       524288.0    known        1        4
0.078842 0.012384      1048576      1048576.0    known        0        4
0.043981 0.009120      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033005
total feature number = 11524636
only testing
raw predictions = tmp/iter070.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter071.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145303 0.045218       524288       524288.0    known        1        4
0.078845 0.012387      1048576      1048576.0    known        0        4
0.043982 0.009118      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033005
total feature number = 11524636
only testing
raw predictions = tmp/iter071.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter072.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145307 0.045226       524288       524288.0    known        1        4
0.078840 0.012372      1048576      1048576.0    known        0        4
0.043978 0.009116      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033000
total feature number = 11524636
only testing
raw predictions = tmp/iter072.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter073.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145310 0.045232       524288       524288.0    known        1        4
0.078838 0.012367      1048576      1048576.0    known        0        4
0.043976 0.009113      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032997
total feature number = 11524636
only testing
raw predictions = tmp/iter073.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter074.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145309 0.045230       524288       524288.0    known        1        4
0.078837 0.012364      1048576      1048576.0    known        0        4
0.043971 0.009106      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032994
total feature number = 11524636
only testing
raw predictions = tmp/iter074.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter075.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145309 0.045229       524288       524288.0    known        1        4
0.078840 0.012372      1048576      1048576.0    known        0        4
0.043970 0.009100      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032994
total feature number = 11524636
only testing
raw predictions = tmp/iter075.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter076.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145309 0.045230       524288       524288.0    known        1        4
0.078837 0.012365      1048576      1048576.0    known        0        4
0.043965 0.009094      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032990
total feature number = 11524636
only testing
raw predictions = tmp/iter076.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter077.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145311 0.045234       524288       524288.0    known        1        4
0.078840 0.012369      1048576      1048576.0    known        0        4
0.043965 0.009091      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032989
total feature number = 11524636
only testing
raw predictions = tmp/iter077.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter078.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145314 0.045239       524288       524288.0    known        1        4
0.078842 0.012371      1048576      1048576.0    known        0        4
0.043962 0.009083      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032986
total feature number = 11524636
only testing
raw predictions = tmp/iter078.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter079.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145318 0.045248       524288       524288.0    known        1        4
0.078852 0.012386      1048576      1048576.0    known        0        4
0.043961 0.009069      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032983
total feature number = 11524636
only testing
raw predictions = tmp/iter079.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter080.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145317 0.045246       524288       524288.0    known        1        4
0.078853 0.012389      1048576      1048576.0    known        0        4
0.043960 0.009067      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032981
total feature number = 11524636
only testing
raw predictions = tmp/iter080.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter081.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145317 0.045246       524288       524288.0    known        1        4
0.078854 0.012390      1048576      1048576.0    known        0        4
0.043958 0.009062      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032979
total feature number = 11524636
only testing
raw predictions = tmp/iter081.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter082.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145312 0.045237       524288       524288.0    known        1        4
0.078854 0.012395      1048576      1048576.0    known        0        4
0.043958 0.009062      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032978
total feature number = 11524636
only testing
raw predictions = tmp/iter082.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter083.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145314 0.045240       524288       524288.0    known        1        4
0.078854 0.012393      1048576      1048576.0    known        0        4
0.043957 0.009060      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032978
total feature number = 11524636
only testing
raw predictions = tmp/iter083.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter084.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145305 0.045222       524288       524288.0    known        1        4
0.078847 0.012388      1048576      1048576.0    known        0        4
0.043952 0.009058      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032975
total feature number = 11524636
only testing
raw predictions = tmp/iter084.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter085.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145304 0.045221       524288       524288.0    known        1        4
0.078843 0.012382      1048576      1048576.0    known        0        4
0.043951 0.009058      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032972
total feature number = 11524636
only testing
raw predictions = tmp/iter085.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter086.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145302 0.045216       524288       524288.0    known        1        4
0.078842 0.012382      1048576      1048576.0    known        0        4
0.043947 0.009053      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032967
total feature number = 11524636
only testing
raw predictions = tmp/iter086.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter087.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145300 0.045212       524288       524288.0    known        1        4
0.078837 0.012373      1048576      1048576.0    known        0        4
0.043937 0.009038      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032956
total feature number = 11524636
only testing
raw predictions = tmp/iter087.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter088.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145296 0.045203       524288       524288.0    known        1        4
0.078833 0.012371      1048576      1048576.0    known        0        4
0.043932 0.009030      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032951
total feature number = 11524636
only testing
raw predictions = tmp/iter088.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter089.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145299 0.045211       524288       524288.0    known        1        4
0.078836 0.012373      1048576      1048576.0    known        0        4
0.043933 0.009029      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032952
total feature number = 11524636
only testing
raw predictions = tmp/iter089.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter090.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145299 0.045210       524288       524288.0    known        1        4
0.078835 0.012371      1048576      1048576.0    known        0        4
0.043933 0.009031      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032952
total feature number = 11524636
only testing
raw predictions = tmp/iter090.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter091.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145306 0.045224       524288       524288.0    known        1        4
0.078838 0.012370      1048576      1048576.0    known        0        4
0.043935 0.009032      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032953
total feature number = 11524636
only testing
raw predictions = tmp/iter091.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter092.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145303 0.045217       524288       524288.0    known        1        4
0.078836 0.012369      1048576      1048576.0    known        0        4
0.043931 0.009025      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032949
total feature number = 11524636
only testing
raw predictions = tmp/iter092.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter093.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145306 0.045224       524288       524288.0    known        1        4
0.078837 0.012368      1048576      1048576.0    known        0        4
0.043929 0.009021      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032948
total feature number = 11524636
only testing
raw predictions = tmp/iter093.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter094.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145297 0.045206       524288       524288.0    known        1        4
0.078833 0.012370      1048576      1048576.0    known        0        4
0.043927 0.009020      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032947
total feature number = 11524636
only testing
raw predictions = tmp/iter094.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter095.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145295 0.045202       524288       524288.0    known        1        4
0.078831 0.012367      1048576      1048576.0    known        0        4
0.043921 0.009012      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032940
total feature number = 11524636
only testing
raw predictions = tmp/iter095.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter096.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145293 0.045197       524288       524288.0    known        1        4
0.078825 0.012357      1048576      1048576.0    known        0        4
0.043916 0.009008      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032935
total feature number = 11524636
only testing
raw predictions = tmp/iter096.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter097.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145296 0.045204       524288       524288.0    known        1        4
0.078823 0.012350      1048576      1048576.0    known        0        4
0.043915 0.009007      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032933
total feature number = 11524636
only testing
raw predictions = tmp/iter097.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter098.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145294 0.045201       524288       524288.0    known        1        4
0.078820 0.012345      1048576      1048576.0    known        0        4
0.043912 0.009005      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032930
total feature number = 11524636
only testing
raw predictions = tmp/iter098.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter099.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145295 0.045202       524288       524288.0    known        1        4
0.078820 0.012346      1048576      1048576.0    known        0        4
0.043912 0.009003      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032930
total feature number = 11524636
only testing
raw predictions = tmp/iter099.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter100.train.nonshared.model
Num weight bits = 25
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        2
1.000000 1.000000            2            2.0    known        1        2
1.000000 1.000000            4            4.0    known        1        2
0.875000 0.750000            8            8.0    known        1        2
0.937500 1.000000           16           16.0    known        1        2
0.687500 0.437500           32           32.0    known        1        2
0.531250 0.375000           64           64.0    known        1        2
0.492188 0.453125          128          128.0    known        1        2
0.468750 0.445312          256          256.0    known        1        2
0.455078 0.441406          512          512.0    known        0        2
0.445312 0.435547         1024         1024.0    known        1        2
0.406250 0.367188         2048         2048.0    known        0        2
0.373047 0.339844         4096         4096.0    known        1        2
0.343018 0.312988         8192         8192.0    known        1        2
0.314026 0.285034        16384        16384.0    known        1        2
0.288940 0.263855        32768        32768.0    known        0        2
0.269958 0.250977        65536        65536.0    known        0        2
0.256409 0.242859       131072       131072.0    known        0        2
0.245388 0.234367       262144       262144.0    known        1        2
0.145294 0.045199       524288       524288.0    known        1        4
0.078817 0.012341      1048576      1048576.0    known        0        4
0.043912 0.009007      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032929
total feature number = 11524636
only testing
raw predictions = tmp/iter100.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        0        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
touch run
./x_progress.sh -fverb_lemma_functor be_ACT be_PAT use_PAT give_PAT take_CPHR take_PAT keep_ACT leave_ACT come_PAT stand_ACT occur_TPAR forward_ADDR fall_REG sink_ACT wonder_TWHEN whisper_ADDR visualize_PAT walk_MANN destroy_MEANS ezeken_ACT forward_COND lift_off_DIR3 >> stats
only testing
raw predictions = tmp/001.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/002.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/003.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/004.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/005.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/006.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/007.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/008.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/009.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/010.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/011.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/012.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/013.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/014.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/015.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/016.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/017.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/018.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/019.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/020.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/021.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/022.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/023.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/024.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/025.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/026.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/027.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/028.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/029.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/030.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/031.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/032.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/033.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/034.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/035.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/036.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/037.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/038.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/039.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/040.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/041.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/042.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/043.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/044.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/045.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/046.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/047.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/048.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/049.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/050.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/051.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/052.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/053.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/054.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/055.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/056.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/057.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/058.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/059.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/060.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/061.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/062.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/063.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/064.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/065.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/066.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/067.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/068.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/069.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/070.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/071.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/072.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/073.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/074.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/075.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/076.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/077.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/078.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/079.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/080.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/081.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/082.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/083.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/084.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/085.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/086.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/087.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/088.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/089.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/090.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/091.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/092.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/093.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/094.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/095.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/096.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/097.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/098.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/099.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
only testing
raw predictions = tmp/100.result.txt
Num weight bits = 25
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        0        2
0.000000 0.000000           16           16.0  unknown        0        2

finished run
number of examples per pass = 22
passes used = 1
weighted example sum = 22.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 44
