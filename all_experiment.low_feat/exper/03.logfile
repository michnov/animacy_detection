./em.sh 100
final_regressor = model/iter001.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
gzip: data/iter000.labeled.train.nonshared.table.gz: No such file or directory
0.226957 0.219471       524288       524288.0    known        0        4
0.218722 0.210487      1048576      1048576.0    known        0        4
0.214016 0.209311      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 282808
passes used = 10
weighted example sum = 2828080.000000
weighted label sum = 0.000000
average loss = 0.212766
total feature number = 11312320
only testing
raw predictions = tmp/iter001.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter002.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.209095 0.183747       524288       524288.0    known        1        4
0.191603 0.174111      1048576      1048576.0    known        0        4
0.182026 0.172450      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.178939
total feature number = 12090252
only testing
raw predictions = tmp/iter002.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter003.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.156623 0.078803       524288       524288.0    known        1        4
0.106333 0.056043      1048576      1048576.0    known        0        4
0.079737 0.053141      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.071338
total feature number = 12090252
only testing
raw predictions = tmp/iter003.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter004.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.143719 0.052994       524288       524288.0    known        1        4
0.084106 0.024493      1048576      1048576.0    known        0        4
0.052557 0.021007      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.042549
total feature number = 12090252
only testing
raw predictions = tmp/iter004.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter005.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.141215 0.047987       524288       524288.0    known        1        4
0.079461 0.017706      1048576      1048576.0    known        0        4
0.046825 0.014190      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.036486
total feature number = 12090252
only testing
raw predictions = tmp/iter005.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter006.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.140374 0.046305       524288       524288.0    known        1        4
0.077927 0.015479      1048576      1048576.0    known        0        4
0.044954 0.011982      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.034539
total feature number = 12090252
only testing
raw predictions = tmp/iter006.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter007.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139961 0.045478       524288       524288.0    known        1        4
0.077172 0.014383      1048576      1048576.0    known        0        4
0.044048 0.010925      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.033599
total feature number = 12090252
only testing
raw predictions = tmp/iter007.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter008.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139711 0.044979       524288       524288.0    known        1        4
0.076673 0.013635      1048576      1048576.0    known        0        4
0.043445 0.010216      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032988
total feature number = 12090252
only testing
raw predictions = tmp/iter008.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter009.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139524 0.044605       524288       524288.0    known        1        4
0.076271 0.013018      1048576      1048576.0    known        0        4
0.042961 0.009650      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032485
total feature number = 12090252
only testing
raw predictions = tmp/iter009.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter010.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139366 0.044288       524288       524288.0    known        1        4
0.075963 0.012561      1048576      1048576.0    known        0        4
0.042551 0.009139      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.032060
total feature number = 12090252
only testing
raw predictions = tmp/iter010.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter011.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139252 0.044060       524288       524288.0    known        1        4
0.075738 0.012223      1048576      1048576.0    known        0        4
0.042251 0.008765      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.031743
total feature number = 12090252
only testing
raw predictions = tmp/iter011.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter012.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139163 0.043883       524288       524288.0    known        1        4
0.075551 0.011939      1048576      1048576.0    known        0        4
0.042033 0.008514      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.031504
total feature number = 12090252
only testing
raw predictions = tmp/iter012.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter013.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139117 0.043790       524288       524288.0    known        1        4
0.075430 0.011743      1048576      1048576.0    known        0        4
0.041870 0.008309      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.031328
total feature number = 12090252
only testing
raw predictions = tmp/iter013.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter014.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139086 0.043729       524288       524288.0    known        1        4
0.075348 0.011610      1048576      1048576.0    known        0        4
0.041744 0.008140      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.031197
total feature number = 12090252
only testing
raw predictions = tmp/iter014.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter015.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139056 0.043668       524288       524288.0    known        1        4
0.075283 0.011509      1048576      1048576.0    known        0        4
0.041642 0.008001      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.031081
total feature number = 12090252
only testing
raw predictions = tmp/iter015.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter016.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139029 0.043615       524288       524288.0    known        1        4
0.075221 0.011413      1048576      1048576.0    known        0        4
0.041546 0.007870      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030972
total feature number = 12090252
only testing
raw predictions = tmp/iter016.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter017.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.139002 0.043560       524288       524288.0    known        1        4
0.075168 0.011334      1048576      1048576.0    known        0        4
0.041467 0.007766      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030887
total feature number = 12090252
only testing
raw predictions = tmp/iter017.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter018.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138982 0.043520       524288       524288.0    known        1        4
0.075119 0.011256      1048576      1048576.0    known        0        4
0.041395 0.007672      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030814
total feature number = 12090252
only testing
raw predictions = tmp/iter018.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter019.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138974 0.043504       524288       524288.0    known        1        4
0.075081 0.011187      1048576      1048576.0    known        0        4
0.041334 0.007587      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030745
total feature number = 12090252
only testing
raw predictions = tmp/iter019.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter020.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138959 0.043475       524288       524288.0    known        1        4
0.075051 0.011143      1048576      1048576.0    known        0        4
0.041282 0.007512      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030681
total feature number = 12090252
only testing
raw predictions = tmp/iter020.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter021.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138956 0.043468       524288       524288.0    known        1        4
0.075032 0.011108      1048576      1048576.0    known        0        4
0.041241 0.007450      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030633
total feature number = 12090252
only testing
raw predictions = tmp/iter021.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter022.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138944 0.043444       524288       524288.0    known        1        4
0.074996 0.011047      1048576      1048576.0    known        0        4
0.041203 0.007411      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030592
total feature number = 12090252
only testing
raw predictions = tmp/iter022.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter023.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138927 0.043410       524288       524288.0    known        1        4
0.074956 0.010985      1048576      1048576.0    known        0        4
0.041138 0.007321      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030524
total feature number = 12090252
only testing
raw predictions = tmp/iter023.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter024.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138902 0.043360       524288       524288.0    known        1        4
0.074902 0.010902      1048576      1048576.0    known        0        4
0.041058 0.007213      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030444
total feature number = 12090252
only testing
raw predictions = tmp/iter024.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter025.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138872 0.043301       524288       524288.0    known        1        4
0.074833 0.010794      1048576      1048576.0    known        0        4
0.040982 0.007130      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030366
total feature number = 12090252
only testing
raw predictions = tmp/iter025.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter026.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138867 0.043291       524288       524288.0    known        1        4
0.074800 0.010733      1048576      1048576.0    known        0        4
0.040927 0.007053      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030305
total feature number = 12090252
only testing
raw predictions = tmp/iter026.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter027.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138862 0.043281       524288       524288.0    known        1        4
0.074775 0.010689      1048576      1048576.0    known        0        4
0.040891 0.007007      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030264
total feature number = 12090252
only testing
raw predictions = tmp/iter027.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter028.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138863 0.043283       524288       524288.0    known        1        4
0.074758 0.010653      1048576      1048576.0    known        0        4
0.040866 0.006975      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030237
total feature number = 12090252
only testing
raw predictions = tmp/iter028.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter029.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138847 0.043251       524288       524288.0    known        1        4
0.074729 0.010611      1048576      1048576.0    known        0        4
0.040838 0.006946      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030211
total feature number = 12090252
only testing
raw predictions = tmp/iter029.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter030.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138835 0.043226       524288       524288.0    known        1        4
0.074699 0.010563      1048576      1048576.0    known        0        4
0.040801 0.006904      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030174
total feature number = 12090252
only testing
raw predictions = tmp/iter030.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter031.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138833 0.043221       524288       524288.0    known        1        4
0.074675 0.010517      1048576      1048576.0    known        0        4
0.040769 0.006863      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030139
total feature number = 12090252
only testing
raw predictions = tmp/iter031.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter032.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138834 0.043224       524288       524288.0    known        1        4
0.074664 0.010495      1048576      1048576.0    known        0        4
0.040747 0.006829      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030112
total feature number = 12090252
only testing
raw predictions = tmp/iter032.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter033.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138826 0.043208       524288       524288.0    known        1        4
0.074658 0.010490      1048576      1048576.0    known        0        4
0.040731 0.006804      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030095
total feature number = 12090252
only testing
raw predictions = tmp/iter033.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter034.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138829 0.043214       524288       524288.0    known        1        4
0.074654 0.010480      1048576      1048576.0    known        0        4
0.040720 0.006786      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030083
total feature number = 12090252
only testing
raw predictions = tmp/iter034.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter035.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138834 0.043224       524288       524288.0    known        1        4
0.074656 0.010479      1048576      1048576.0    known        0        4
0.040712 0.006768      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030074
total feature number = 12090252
only testing
raw predictions = tmp/iter035.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter036.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138835 0.043227       524288       524288.0    known        1        4
0.074655 0.010476      1048576      1048576.0    known        0        4
0.040705 0.006754      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030062
total feature number = 12090252
only testing
raw predictions = tmp/iter036.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter037.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138828 0.043213       524288       524288.0    known        1        4
0.074648 0.010467      1048576      1048576.0    known        0        4
0.040696 0.006743      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030052
total feature number = 12090252
only testing
raw predictions = tmp/iter037.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter038.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138827 0.043211       524288       524288.0    known        1        4
0.074642 0.010456      1048576      1048576.0    known        0        4
0.040688 0.006734      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030043
total feature number = 12090252
only testing
raw predictions = tmp/iter038.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter039.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138824 0.043205       524288       524288.0    known        1        4
0.074633 0.010442      1048576      1048576.0    known        0        4
0.040675 0.006717      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030030
total feature number = 12090252
only testing
raw predictions = tmp/iter039.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter040.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138816 0.043189       524288       524288.0    known        1        4
0.074622 0.010428      1048576      1048576.0    known        0        4
0.040663 0.006704      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030017
total feature number = 12090252
only testing
raw predictions = tmp/iter040.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter041.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138813 0.043183       524288       524288.0    known        1        4
0.074618 0.010423      1048576      1048576.0    known        0        4
0.040653 0.006689      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.030007
total feature number = 12090252
only testing
raw predictions = tmp/iter041.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter042.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138813 0.043183       524288       524288.0    known        1        4
0.074614 0.010415      1048576      1048576.0    known        0        4
0.040645 0.006676      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029998
total feature number = 12090252
only testing
raw predictions = tmp/iter042.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter043.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138812 0.043181       524288       524288.0    known        1        4
0.074611 0.010409      1048576      1048576.0    known        0        4
0.040638 0.006666      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029993
total feature number = 12090252
only testing
raw predictions = tmp/iter043.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter044.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138810 0.043175       524288       524288.0    known        1        4
0.074604 0.010399      1048576      1048576.0    known        0        4
0.040629 0.006654      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029983
total feature number = 12090252
only testing
raw predictions = tmp/iter044.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter045.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138812 0.043181       524288       524288.0    known        1        4
0.074600 0.010387      1048576      1048576.0    known        0        4
0.040622 0.006645      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029973
total feature number = 12090252
only testing
raw predictions = tmp/iter045.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter046.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138815 0.043186       524288       524288.0    known        1        4
0.074598 0.010381      1048576      1048576.0    known        0        4
0.040617 0.006636      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029967
total feature number = 12090252
only testing
raw predictions = tmp/iter046.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter047.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138811 0.043178       524288       524288.0    known        1        4
0.074590 0.010369      1048576      1048576.0    known        0        4
0.040607 0.006624      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029958
total feature number = 12090252
only testing
raw predictions = tmp/iter047.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter048.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138810 0.043177       524288       524288.0    known        1        4
0.074583 0.010355      1048576      1048576.0    known        0        4
0.040597 0.006611      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029946
total feature number = 12090252
only testing
raw predictions = tmp/iter048.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter049.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138813 0.043183       524288       524288.0    known        1        4
0.074578 0.010343      1048576      1048576.0    known        0        4
0.040589 0.006599      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029937
total feature number = 12090252
only testing
raw predictions = tmp/iter049.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter050.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138815 0.043186       524288       524288.0    known        1        4
0.074573 0.010331      1048576      1048576.0    known        0        4
0.040583 0.006592      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029932
total feature number = 12090252
only testing
raw predictions = tmp/iter050.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter051.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138814 0.043184       524288       524288.0    known        1        4
0.074573 0.010332      1048576      1048576.0    known        0        4
0.040581 0.006589      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029928
total feature number = 12090252
only testing
raw predictions = tmp/iter051.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter052.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138817 0.043191       524288       524288.0    known        1        4
0.074571 0.010325      1048576      1048576.0    known        0        4
0.040579 0.006586      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029926
total feature number = 12090252
only testing
raw predictions = tmp/iter052.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter053.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138821 0.043198       524288       524288.0    known        1        4
0.074569 0.010317      1048576      1048576.0    known        0        4
0.040575 0.006581      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029922
total feature number = 12090252
only testing
raw predictions = tmp/iter053.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter054.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138821 0.043199       524288       524288.0    known        1        4
0.074566 0.010311      1048576      1048576.0    known        0        4
0.040573 0.006580      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029920
total feature number = 12090252
only testing
raw predictions = tmp/iter054.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter055.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138818 0.043193       524288       524288.0    known        1        4
0.074563 0.010308      1048576      1048576.0    known        0        4
0.040571 0.006580      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029918
total feature number = 12090252
only testing
raw predictions = tmp/iter055.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter056.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138820 0.043197       524288       524288.0    known        1        4
0.074565 0.010309      1048576      1048576.0    known        0        4
0.040571 0.006577      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029917
total feature number = 12090252
only testing
raw predictions = tmp/iter056.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter057.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138818 0.043192       524288       524288.0    known        1        4
0.074562 0.010305      1048576      1048576.0    known        0        4
0.040566 0.006571      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029913
total feature number = 12090252
only testing
raw predictions = tmp/iter057.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter058.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138814 0.043184       524288       524288.0    known        1        4
0.074552 0.010290      1048576      1048576.0    known        0        4
0.040556 0.006561      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029905
total feature number = 12090252
only testing
raw predictions = tmp/iter058.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter059.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138812 0.043179       524288       524288.0    known        1        4
0.074549 0.010287      1048576      1048576.0    known        0        4
0.040552 0.006554      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029900
total feature number = 12090252
only testing
raw predictions = tmp/iter059.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter060.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138811 0.043178       524288       524288.0    known        1        4
0.074549 0.010287      1048576      1048576.0    known        0        4
0.040552 0.006554      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029900
total feature number = 12090252
only testing
raw predictions = tmp/iter060.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter061.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138810 0.043177       524288       524288.0    known        1        4
0.074553 0.010297      1048576      1048576.0    known        0        4
0.040554 0.006554      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029902
total feature number = 12090252
only testing
raw predictions = tmp/iter061.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter062.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138808 0.043172       524288       524288.0    known        1        4
0.074551 0.010294      1048576      1048576.0    known        0        4
0.040553 0.006556      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029901
total feature number = 12090252
only testing
raw predictions = tmp/iter062.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter063.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138810 0.043176       524288       524288.0    known        1        4
0.074551 0.010292      1048576      1048576.0    known        0        4
0.040551 0.006552      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029899
total feature number = 12090252
only testing
raw predictions = tmp/iter063.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter064.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138808 0.043172       524288       524288.0    known        1        4
0.074549 0.010290      1048576      1048576.0    known        0        4
0.040549 0.006549      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029897
total feature number = 12090252
only testing
raw predictions = tmp/iter064.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter065.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138809 0.043174       524288       524288.0    known        1        4
0.074547 0.010286      1048576      1048576.0    known        0        4
0.040548 0.006548      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029896
total feature number = 12090252
only testing
raw predictions = tmp/iter065.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter066.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138807 0.043171       524288       524288.0    known        1        4
0.074546 0.010286      1048576      1048576.0    known        0        4
0.040544 0.006542      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029892
total feature number = 12090252
only testing
raw predictions = tmp/iter066.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter067.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138803 0.043162       524288       524288.0    known        1        4
0.074543 0.010284      1048576      1048576.0    known        0        4
0.040539 0.006535      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029886
total feature number = 12090252
only testing
raw predictions = tmp/iter067.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter068.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138797 0.043151       524288       524288.0    known        1        4
0.074538 0.010278      1048576      1048576.0    known        0        4
0.040532 0.006527      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029880
total feature number = 12090252
only testing
raw predictions = tmp/iter068.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter069.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138795 0.043146       524288       524288.0    known        1        4
0.074536 0.010277      1048576      1048576.0    known        0        4
0.040530 0.006525      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029878
total feature number = 12090252
only testing
raw predictions = tmp/iter069.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter070.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138796 0.043149       524288       524288.0    known        1        4
0.074535 0.010275      1048576      1048576.0    known        0        4
0.040530 0.006524      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029877
total feature number = 12090252
only testing
raw predictions = tmp/iter070.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter071.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138797 0.043150       524288       524288.0    known        1        4
0.074536 0.010275      1048576      1048576.0    known        0        4
0.040528 0.006520      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029874
total feature number = 12090252
only testing
raw predictions = tmp/iter071.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter072.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138797 0.043150       524288       524288.0    known        1        4
0.074535 0.010274      1048576      1048576.0    known        0        4
0.040526 0.006516      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029872
total feature number = 12090252
only testing
raw predictions = tmp/iter072.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter073.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138798 0.043152       524288       524288.0    known        1        4
0.074536 0.010274      1048576      1048576.0    known        0        4
0.040525 0.006513      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029871
total feature number = 12090252
only testing
raw predictions = tmp/iter073.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter074.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138798 0.043152       524288       524288.0    known        1        4
0.074535 0.010272      1048576      1048576.0    known        0        4
0.040524 0.006512      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029870
total feature number = 12090252
only testing
raw predictions = tmp/iter074.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter075.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138798 0.043153       524288       524288.0    known        1        4
0.074535 0.010272      1048576      1048576.0    known        0        4
0.040524 0.006512      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029870
total feature number = 12090252
only testing
raw predictions = tmp/iter075.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter076.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138798 0.043152       524288       524288.0    known        1        4
0.074535 0.010273      1048576      1048576.0    known        0        4
0.040523 0.006511      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029869
total feature number = 12090252
only testing
raw predictions = tmp/iter076.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter077.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138798 0.043153       524288       524288.0    known        1        4
0.074536 0.010273      1048576      1048576.0    known        0        4
0.040523 0.006511      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029869
total feature number = 12090252
only testing
raw predictions = tmp/iter077.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter078.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138798 0.043153       524288       524288.0    known        1        4
0.074534 0.010270      1048576      1048576.0    known        0        4
0.040522 0.006510      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029868
total feature number = 12090252
only testing
raw predictions = tmp/iter078.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter079.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138800 0.043157       524288       524288.0    known        1        4
0.074534 0.010267      1048576      1048576.0    known        0        4
0.040522 0.006510      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029868
total feature number = 12090252
only testing
raw predictions = tmp/iter079.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter080.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138800 0.043157       524288       524288.0    known        1        4
0.074533 0.010266      1048576      1048576.0    known        0        4
0.040521 0.006510      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029867
total feature number = 12090252
only testing
raw predictions = tmp/iter080.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter081.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138802 0.043161       524288       524288.0    known        1        4
0.074534 0.010266      1048576      1048576.0    known        0        4
0.040521 0.006509      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029867
total feature number = 12090252
only testing
raw predictions = tmp/iter081.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter082.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138802 0.043160       524288       524288.0    known        1        4
0.074534 0.010267      1048576      1048576.0    known        0        4
0.040521 0.006508      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029867
total feature number = 12090252
only testing
raw predictions = tmp/iter082.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter083.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138801 0.043159       524288       524288.0    known        1        4
0.074533 0.010266      1048576      1048576.0    known        0        4
0.040520 0.006507      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029866
total feature number = 12090252
only testing
raw predictions = tmp/iter083.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter084.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138803 0.043162       524288       524288.0    known        1        4
0.074534 0.010265      1048576      1048576.0    known        0        4
0.040520 0.006506      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029865
total feature number = 12090252
only testing
raw predictions = tmp/iter084.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter085.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138804 0.043163       524288       524288.0    known        1        4
0.074535 0.010266      1048576      1048576.0    known        0        4
0.040521 0.006507      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029866
total feature number = 12090252
only testing
raw predictions = tmp/iter085.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter086.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138803 0.043163       524288       524288.0    known        1        4
0.074534 0.010264      1048576      1048576.0    known        0        4
0.040521 0.006509      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029866
total feature number = 12090252
only testing
raw predictions = tmp/iter086.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter087.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138801 0.043159       524288       524288.0    known        1        4
0.074533 0.010264      1048576      1048576.0    known        0        4
0.040521 0.006509      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029867
total feature number = 12090252
only testing
raw predictions = tmp/iter087.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter088.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138800 0.043157       524288       524288.0    known        1        4
0.074532 0.010263      1048576      1048576.0    known        0        4
0.040520 0.006508      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029866
total feature number = 12090252
only testing
raw predictions = tmp/iter088.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter089.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138796 0.043148       524288       524288.0    known        1        4
0.074528 0.010261      1048576      1048576.0    known        0        4
0.040517 0.006505      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029862
total feature number = 12090252
only testing
raw predictions = tmp/iter089.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter090.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138795 0.043147       524288       524288.0    known        1        4
0.074528 0.010261      1048576      1048576.0    known        0        4
0.040516 0.006504      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029861
total feature number = 12090252
only testing
raw predictions = tmp/iter090.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter091.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138794 0.043145       524288       524288.0    known        1        4
0.074528 0.010261      1048576      1048576.0    known        0        4
0.040515 0.006502      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029861
total feature number = 12090252
only testing
raw predictions = tmp/iter091.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter092.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138794 0.043144       524288       524288.0    known        1        4
0.074528 0.010263      1048576      1048576.0    known        0        4
0.040515 0.006501      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029861
total feature number = 12090252
only testing
raw predictions = tmp/iter092.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter093.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138797 0.043150       524288       524288.0    known        1        4
0.074529 0.010262      1048576      1048576.0    known        0        4
0.040515 0.006501      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029861
total feature number = 12090252
only testing
raw predictions = tmp/iter093.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter094.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138796 0.043149       524288       524288.0    known        1        4
0.074527 0.010258      1048576      1048576.0    known        0        4
0.040513 0.006500      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029860
total feature number = 12090252
only testing
raw predictions = tmp/iter094.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter095.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138796 0.043148       524288       524288.0    known        1        4
0.074526 0.010257      1048576      1048576.0    known        0        4
0.040513 0.006499      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029860
total feature number = 12090252
only testing
raw predictions = tmp/iter095.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter096.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138795 0.043146       524288       524288.0    known        1        4
0.074527 0.010258      1048576      1048576.0    known        0        4
0.040512 0.006498      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029859
total feature number = 12090252
only testing
raw predictions = tmp/iter096.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter097.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138794 0.043145       524288       524288.0    known        1        4
0.074525 0.010256      1048576      1048576.0    known        0        4
0.040511 0.006497      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029858
total feature number = 12090252
only testing
raw predictions = tmp/iter097.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter098.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138795 0.043146       524288       524288.0    known        1        4
0.074525 0.010254      1048576      1048576.0    known        0        4
0.040510 0.006495      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029856
total feature number = 12090252
only testing
raw predictions = tmp/iter098.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter099.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138796 0.043149       524288       524288.0    known        1        4
0.074523 0.010249      1048576      1048576.0    known        0        4
0.040507 0.006492      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029853
total feature number = 12090252
only testing
raw predictions = tmp/iter099.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
final_regressor = model/iter100.train.nonshared.model
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
creating cache_file = vw.cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    known        1        4
0.500000 0.000000            2            2.0    known        0        4
0.250000 0.000000            4            4.0    known        0        4
0.250000 0.250000            8            8.0    known        0        4
0.250000 0.250000           16           16.0    known        0        4
0.406250 0.562500           32           32.0    known        0        4
0.484375 0.562500           64           64.0    known        0        4
0.359375 0.234375          128          128.0    known        1        4
0.328125 0.296875          256          256.0    known        1        4
0.353516 0.378906          512          512.0    known        0        4
0.319336 0.285156         1024         1024.0    known        0        4
0.313477 0.307617         2048         2048.0    known        0        4
0.306396 0.299316         4096         4096.0    known        0        4
0.288086 0.269775         8192         8192.0    known        1        4
0.272461 0.256836        16384        16384.0    known        1        4
0.261292 0.250122        32768        32768.0    known        0        4
0.249100 0.236908        65536        65536.0    known        0        4
0.240547 0.231995       131072       131072.0    known        0        4
0.234444 0.228340       262144       262144.0    known        1        4
0.138798 0.043151       524288       524288.0    known        1        4
0.074523 0.010248      1048576      1048576.0    known        0        4
0.040507 0.006491      2097152      2097152.0    known        0        4

finished run
number of examples per pass = 3022563
passes used = 1
weighted example sum = 3022563.000000
weighted label sum = 0.000000
average loss = 0.029852
total feature number = 12090252
only testing
raw predictions = tmp/iter100.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        4
0.000000 0.000000            2            2.0  unknown        1        4
0.000000 0.000000            4            4.0  unknown        1        4
0.000000 0.000000            8            8.0  unknown        0        4
0.000000 0.000000           16           16.0  unknown        1        4
0.000000 0.000000           32           32.0  unknown        1        4
0.000000 0.000000           64           64.0  unknown        1        4
0.000000 0.000000          128          128.0  unknown        1        4
0.000000 0.000000          256          256.0  unknown        1        4
0.000000 0.000000          512          512.0  unknown        1        4
0.000000 0.000000         1024         1024.0  unknown        0        4
0.000000 0.000000         2048         2048.0  unknown        1        4
0.000000 0.000000         4096         4096.0  unknown        1        4
0.000000 0.000000         8192         8192.0  unknown        0        4
0.000000 0.000000        16384        16384.0  unknown        1        4
0.000000 0.000000        32768        32768.0  unknown        0        4
0.000000 0.000000        65536        65536.0  unknown        1        4
0.000000 0.000000       131072       131072.0  unknown        1        4
0.000000 0.000000       262144       262144.0  unknown        0        4
0.000000 0.000000       524288       524288.0  unknown        1        4
0.000000 0.000000      1048576      1048576.0  unknown        1        4
0.000000 0.000000      2097152      2097152.0  unknown        1        4

finished run
number of examples per pass = 2739755
passes used = 1
weighted example sum = 2739755.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 10959020
Pasting results to unlabeled.train.nonshared.table.gz
Processing instane no. 100000
Processing instane no. 200000
Processing instane no. 300000
Processing instane no. 400000
Processing instane no. 500000
Processing instane no. 600000
Processing instane no. 700000
Processing instane no. 800000
Processing instane no. 900000
Processing instane no. 1000000
Processing instane no. 1100000
Processing instane no. 1200000
Processing instane no. 1300000
Processing instane no. 1400000
Processing instane no. 1500000
Processing instane no. 1600000
Processing instane no. 1700000
Processing instane no. 1800000
Processing instane no. 1900000
Processing instane no. 2000000
Processing instane no. 2100000
Processing instane no. 2200000
Processing instane no. 2300000
Processing instane no. 2400000
Processing instane no. 2500000
Processing instane no. 2600000
Processing instane no. 2700000
touch run
./x_progress.sh -fkid_lemma John Mary boy girl man woman dog cat elephant computer table axe space government reason >> stats
only testing
raw predictions = tmp/001.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        1        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/002.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/003.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/004.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/005.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/006.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/007.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/008.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/009.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/010.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/011.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/012.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/013.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/014.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/015.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/016.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/017.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/018.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/019.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        0        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/020.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        0        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/021.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/022.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/023.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/024.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/025.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/026.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/027.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/028.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/029.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/030.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/031.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/032.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/033.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/034.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/035.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/036.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/037.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/038.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/039.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        0        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/040.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/041.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/042.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/043.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/044.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/045.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/046.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/047.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/048.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/049.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/050.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/051.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/052.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/053.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/054.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/055.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/056.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/057.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/058.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/059.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/060.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/061.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/062.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/063.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/064.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/065.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/066.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/067.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/068.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/069.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/070.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/071.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/072.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/073.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/074.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/075.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/076.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/077.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/078.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/079.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/080.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/081.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/082.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/083.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/084.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/085.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/086.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/087.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/088.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/089.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/090.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/091.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/092.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/093.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/094.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/095.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/096.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/097.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/098.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/099.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
only testing
raw predictions = tmp/100.result.txt
Num weight bits = 20
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0  unknown        0        2
0.000000 0.000000            2            2.0  unknown        1        2
0.000000 0.000000            4            4.0  unknown        1        2
0.000000 0.000000            8            8.0  unknown        1        2

finished run
number of examples per pass = 15
passes used = 1
weighted example sum = 15.000000
weighted label sum = 0.000000
average loss = 0.000000
total feature number = 30
